{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e316e590",
   "metadata": {},
   "source": [
    "Processing of Depressed- Resting Imperial "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6009e3",
   "metadata": {},
   "source": [
    "The source dataset is a bit of a nightmare. I used the continuos one. \n",
    "\n",
    "The data are in data_clip. trials. However, there are different numbers of trials (up to 400) that are stored in different cells in the trials path. In those datasets the rows are the channels and the column the time. Therefore, each of the trials has to be extracted, transposed and then concatenated with the other trials. The channels are in a separate channel file where the labels are listed in one row under dataclip.label. Then this needs to be brought into the 3d array. \n",
    "\n",
    "Problem is:\n",
    "- the recordings are of different length. Up until now I cropped them to the minimum length to put them into the array (con:loosing data)\n",
    "- the information of the markers was written for the epoched files, therefore we cannot just determine from the timepoints when something happenened. The epoched data is stored in epochs of consuistent lengths so we can infer the value like that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b3c218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "folder = r'C:\\Users\\s2364956\\Desktop\\Data\\ComplexSystems\\Ketamine\\Depressed\\Resting_imperial'\n",
    "all_eeg_data = []  # List to store EEG data for all recordings\n",
    "filenames = []\n",
    "\n",
    "for fname in os.listdir(folder):\n",
    "    if not (fname.endswith('.mat') and 'continuous' in fname.lower()):\n",
    "        continue\n",
    "    \n",
    "    path = os.path.join(folder, fname)\n",
    "    try:\n",
    "        mat = loadmat(path, struct_as_record=False, squeeze_me=True)\n",
    "        \n",
    "        # Extract relevant data\n",
    "        data = mat['data_clip']\n",
    "        trials = data.trial  # This is a cell array where each cell is a trial\n",
    "        times = data.time  # Time corresponding to each trial (n_samples,)\n",
    "\n",
    "        # Prepare a list to store all trials' data within this recording\n",
    "        trials_data = []\n",
    "\n",
    "        # Process each trial (trials is a list of cells, each containing trial data)\n",
    "        for trial_idx, trial in enumerate(np.atleast_1d(trials)):\n",
    "            if trial.size == 0:\n",
    "                continue\n",
    "            \n",
    "            # Each trial is a (n_channels, n_samples) array.\n",
    "            # Transpose it to have time as rows and channels as columns.\n",
    "            trial_data = trial.T  # Shape will be (n_samples, n_channels) -> (n_timepoints, n_channels)\n",
    "\n",
    "            # Add the trial data to the list\n",
    "            trials_data.append(trial_data)\n",
    "\n",
    "        # Stack all trials within the current recording (along the time axis)\n",
    "        eeg_data_recording = np.vstack(trials_data)  # Stack vertically (along time dimension)\n",
    "\n",
    "        # Append this recording's data to the list of all EEG data\n",
    "        all_eeg_data.append(eeg_data_recording)\n",
    "        filenames.append(fname)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {fname}: {e}\")\n",
    "\n",
    "\n",
    "# After processing all files, checkinglengths \n",
    "for idx, recording in enumerate(all_eeg_data):\n",
    "    n_samples = recording.shape[0]  # Number of time points (rows)\n",
    "    print(f\"Recording {filenames[idx]}: {n_samples} samples\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Find minimum number of samples across all recordings\n",
    "min_samples = min(recording.shape[0] for recording in all_eeg_data)\n",
    "print(f\"Minimum number of samples across recordings: {min_samples}\")\n",
    "\n",
    "# Trim each recording to the minimum number of samples\n",
    "all_eeg_data_trimmed = [rec[:min_samples, :] for rec in all_eeg_data]\n",
    "\n",
    "# Now you can safely convert to 3D array\n",
    "eeg_3d = np.stack(all_eeg_data_trimmed, axis=0)\n",
    "\n",
    "print(f\"\\nTrimmed EEG Data Shape (Recordings × Time/Samples × Channels): {eeg_3d.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c92599",
   "metadata": {},
   "source": [
    "restacking so the channels are in the 2rd dimension of the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ffb2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack first (time as rows, channels as columns)\n",
    "eeg_3d = np.stack(all_eeg_data_trimmed, axis=0)  # shape (29, min_samples, 63)\n",
    "\n",
    "# Swap axes to (29, 63, min_samples)\n",
    "eeg_3d = np.transpose(eeg_3d, (0, 2, 1))\n",
    "\n",
    "print(f\"Final EEG shape: {eeg_3d.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
