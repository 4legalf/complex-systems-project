{"cells":[{"cell_type":"markdown","id":"d20c6f9e","metadata":{"id":"d20c6f9e"},"source":["Pre-processing of part of the ketamine data, the .mat file seems to contain some wrong information (states only 701 samples per electrodes have been collected)\n","\n","The original data is saved in .mat (description) and .dat (c\n","\n","Until now only locally, because collab isnt collaborating"]},{"cell_type":"code","execution_count":null,"id":"dfe02310","metadata":{"id":"dfe02310","outputId":"22ed031c-db00-4d7b-f7e4-077887307d71"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processed: FullcbeffMspmeeg_KETDEP0017_Day1_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP002_Day1_LTPPre1_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP003_Day2_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP004_Day2_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP005_Day1_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP008_Day1_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP009_Day1_LTPPre1_ICACleaned.mat | Shape: (64, 499813)\n","Processed: FullcbeffMspmeeg_KETDEP010_Day2_LTPPre_ICACleaned.mat | Shape: (64, 556594)\n","Processed: FullcbeffMspmeeg_KETDEP011_Day2_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP013_Day2_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP014_Day1_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP014_Day2_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP015_Day1_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP016_Day2_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP018_Day1_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP019_Day1_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP021_Day2_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP025_Day2_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP030_Day2_LTPPre1_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP031_Day2_LTPPre1_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP032_Day2_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP033_Day1_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP034_Day2_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP035_Day2_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP20_Day2_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP23_Day2_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP24_Day2_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP26_Day1_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP27_Day2_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP28_Day1_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","Processed: FullcbeffMspmeeg_KETDEP29_Day1_LTPPre_ICACleaned.mat | Shape: (64, 504720)\n","\n","3D Array Shape (Files × Channels × Samples): (31, 64, 499813)\n"]}],"source":["import os\n","import numpy as np\n","from scipy.io import loadmat\n","import pandas as pd\n","\n","# Define the directory path\n","data_dir = r\"C:\\Users\\s2364956\\Desktop\\Data\\ComplexSystems\\Ketamine\\Depressed\\LTP_imperial\"\n","\n","# Initialize lists to store data and metadata\n","all_eeg_data = []  # For 3D array (n_files × n_channels × n_samples)\n","file_names = []\n","channel_names = None\n","fsample = None\n","\n","# Loop through all .mat files in the directory\n","for mat_file in sorted(os.listdir(data_dir)):\n","    if mat_file.endswith('.mat'):\n","        mat_path = os.path.join(data_dir, mat_file)\n","\n","        # Load .mat file\n","        cmeta = loadmat(mat_path)\n","        D = cmeta['D'][0, 0]\n","\n","        # Extract metadata (only once, assuming consistency across files)\n","        if channel_names is None:\n","            n_channels = len(D['channels'][0])\n","            channel_names = [str(ch[0]) for ch in D['channels'][0]]\n","            fsample = int(D['Fsample'][0][0])\n","\n","        # Load paired .dat file\n","        dat_path = mat_path.replace('.mat', '.dat')\n","        continuous_data = np.fromfile(dat_path, dtype='float32')\n","        n_samples_total = continuous_data.size // n_channels\n","        eeg_data = continuous_data.reshape((n_channels, n_samples_total), order='F')\n","\n","        # Store in list\n","        all_eeg_data.append(eeg_data)\n","        file_names.append(mat_file)\n","        print(f\"Processed: {mat_file} | Shape: {eeg_data.shape}\")\n","\n","# Stack all files into a 3D array (n_files × n_channels × n_samples)\n","# Note: Assumes all files have the same n_samples_total! If not, pad/truncate.\n","min_samples = min(arr.shape[1] for arr in all_eeg_data)  # Use smallest n_samples if inconsistent\n","eeg_3d = np.stack([arr[:, :min_samples] for arr in all_eeg_data])\n","\n","print(\"\\n3D Array Shape (Files × Channels × Samples):\", eeg_3d.shape)"]},{"cell_type":"code","execution_count":null,"id":"65cab599","metadata":{"id":"65cab599","outputId":"33713905-3483-4801-ddf0-f1888024ab7b"},"outputs":[{"name":"stdout","output_type":"stream","text":["First 5 time points for file: FullcbeffMspmeeg_KETDEP0017_Day1_LTPPre_ICACleaned.mat\n","Sampling rate: 1000 Hz\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>['Fp1']</th>\n","      <th>['Fp2']</th>\n","      <th>['F7']</th>\n","      <th>['F3']</th>\n","      <th>...</th>\n","      <th>['PO3']</th>\n","      <th>['POz']</th>\n","      <th>['PO4']</th>\n","      <th>['PO8']</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0.0000s</th>\n","      <td>-6.419561</td>\n","      <td>-5.155789</td>\n","      <td>-7.589287</td>\n","      <td>-2.592353</td>\n","      <td>...</td>\n","      <td>5.220371</td>\n","      <td>1.396340</td>\n","      <td>0.635933</td>\n","      <td>1.679263</td>\n","    </tr>\n","    <tr>\n","      <th>0.0010s</th>\n","      <td>-6.526850</td>\n","      <td>-5.101662</td>\n","      <td>-7.303430</td>\n","      <td>-2.576094</td>\n","      <td>...</td>\n","      <td>5.133623</td>\n","      <td>1.251419</td>\n","      <td>0.655041</td>\n","      <td>1.749535</td>\n","    </tr>\n","    <tr>\n","      <th>0.0020s</th>\n","      <td>-6.652922</td>\n","      <td>-5.005090</td>\n","      <td>-7.013856</td>\n","      <td>-2.586167</td>\n","      <td>...</td>\n","      <td>5.023960</td>\n","      <td>1.096253</td>\n","      <td>0.677728</td>\n","      <td>1.816788</td>\n","    </tr>\n","    <tr>\n","      <th>0.0030s</th>\n","      <td>-6.795858</td>\n","      <td>-4.869094</td>\n","      <td>-6.728922</td>\n","      <td>-2.621862</td>\n","      <td>...</td>\n","      <td>4.894469</td>\n","      <td>0.934003</td>\n","      <td>0.703041</td>\n","      <td>1.883018</td>\n","    </tr>\n","    <tr>\n","      <th>0.0040s</th>\n","      <td>-6.954254</td>\n","      <td>-4.697541</td>\n","      <td>-6.457341</td>\n","      <td>-2.682146</td>\n","      <td>...</td>\n","      <td>4.748647</td>\n","      <td>0.768209</td>\n","      <td>0.730564</td>\n","      <td>1.951272</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 64 columns</p>\n","</div>"],"text/plain":["          ['Fp1']   ['Fp2']    ['F7']    ['F3']  ...   ['PO3']   ['POz']   ['PO4']   ['PO8']\n","0.0000s -6.419561 -5.155789 -7.589287 -2.592353  ...  5.220371  1.396340  0.635933  1.679263\n","0.0010s -6.526850 -5.101662 -7.303430 -2.576094  ...  5.133623  1.251419  0.655041  1.749535\n","0.0020s -6.652922 -5.005090 -7.013856 -2.586167  ...  5.023960  1.096253  0.677728  1.816788\n","0.0030s -6.795858 -4.869094 -6.728922 -2.621862  ...  4.894469  0.934003  0.703041  1.883018\n","0.0040s -6.954254 -4.697541 -6.457341 -2.682146  ...  4.748647  0.768209  0.730564  1.951272\n","\n","[5 rows x 64 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# create the time vector based on the minimum samples and sampling rate\n","time_vector = np.arange(min_samples) / fsample  # Time in seconds\n","\n","# Now select the first file's data and create a DataFrame\n","first_file_data = eeg_3d[0]  # Shape: (n_channels, min_samples)\n","\n","# Create DataFrame for first 5 time points\n","df_first_5 = pd.DataFrame(\n","    first_file_data[:, :5].T,  # Transpose to (5 samples × n_channels)\n","    columns=channel_names,\n","    index=[f\"{t:.4f}s\" for t in time_vector[:5]]  # Format time labels\n",")\n","\n","# Set display options\n","pd.set_option('display.max_columns', 8)  # Show 8 channels at a time\n","pd.set_option('display.width', 1000)    # Prevent column wrapping\n","\n","print(f\"First 5 time points for file: {file_names[0]}\")\n","print(f\"Sampling rate: {fsample} Hz\")\n","display(df_first_5)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}